{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Initialize Hugging Face summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Data ingestion function\n",
        "def ingest_data(file):\n",
        "    if file.filename.endswith('.csv'):\n",
        "        data = pd.read_csv(file)\n",
        "    elif file.filename.endswith('.json'):\n",
        "        data = pd.read_json(file)\n",
        "    else:\n",
        "        return \"Unsupported file format\", 400\n",
        "    data.to_json('sales_data.json', orient='records')  # Save the data\n",
        "    return data\n",
        "\n",
        "# Function to format individual data as text\n",
        "def format_individual_data(data):\n",
        "    # Create a summary string using relevant columns\n",
        "    summary = f\"Employee ID: {data['employee_id'].values[0]}\\n\"\n",
        "    summary += f\"Employee Name: {data['employee_name'].values[0]}\\n\"\n",
        "    summary += f\"Date: {data['dated'].values[0]}\\n\"\n",
        "    summary += f\"Leads Taken: {data['lead_taken'].values[0]}\\n\"\n",
        "    summary += f\"Tours Booked: {data['tours_booked'].values[0]}\\n\"\n",
        "    summary += f\"Applications: {data['applications'].values[0]}\\n\"\n",
        "    summary += f\"Tours per Lead: {data['tours_per_lead'].values[0]}\\n\"\n",
        "    summary += f\"Apps per Tour: {data['apps_per_tour'].values[0]}\\n\"\n",
        "    summary += f\"Revenue Confirmed: {data['revenue_confirmed'].values[0]}\\n\"\n",
        "    summary += f\"Revenue Pending: {data['revenue_pending'].values[0]}\\n\"\n",
        "    return summary\n",
        "\n",
        "# Function to format team data as text\n",
        "def format_team_data(data):\n",
        "    total_leads = data['lead_taken'].sum()\n",
        "    total_tours = data['tours_booked'].sum()\n",
        "    total_revenue_confirmed = data['revenue_confirmed'].sum()\n",
        "    avg_close_rate = data['avg_close_rate_30_days'].mean()\n",
        "    summary = f\"Total Leads Taken: {total_leads}\\n\"\n",
        "    summary += f\"Total Tours Booked: {total_tours}\\n\"\n",
        "    summary += f\"Total Revenue Confirmed: {total_revenue_confirmed}\\n\"\n",
        "    summary += f\"Average Close Rate (30 days): {avg_close_rate}\\n\"\n",
        "    return summary\n",
        "\n",
        "# Function to analyze data with Hugging Face\n",
        "\n",
        "def analyze_data(data, query):\n",
        "    # Create a more specific prompt for individual or team performance analysis\n",
        "    prompt = (\n",
        "        f\"You are an expert sales analyst. Based on the following sales data, {query}. \"\n",
        "        f\"Here is the data: {data}. Please provide detailed feedback and actionable insights.\"\n",
        "    )\n",
        "    response = summarizer(\n",
        "        prompt,\n",
        "        max_length=150,\n",
        "        min_length=50,\n",
        "        do_sample=False,\n",
        "        clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return response[0]['summary_text']\n",
        "\n",
        "\n",
        "@app.route('/individual/<name>', methods=['GET'])\n",
        "def individual_performance(name):\n",
        "    data = pd.read_json('sales_data.json')\n",
        "    individual_data = data[data['employee_name'] == name]  # Ensure correct employee name matching\n",
        "    if individual_data.empty:\n",
        "        return jsonify({\"error\": \"No data found for the specified employee.\"}), 404\n",
        "\n",
        "    # Format the data for readability in the LLM prompt\n",
        "    formatted_data = individual_data.to_dict(orient='records')[0]  # Convert to dictionary for clear prompt\n",
        "    feedback = analyze_data(formatted_data, \"provide feedback on individual performance\")\n",
        "\n",
        "    return jsonify({\"feedback\": feedback})\n",
        "\n",
        "# Upload endpoint\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return \"No file part\", 400\n",
        "    file = request.files['file']\n",
        "    data = ingest_data(file)\n",
        "    if isinstance(data, tuple):\n",
        "        return data  # Error response\n",
        "    return jsonify({\"message\": \"Data uploaded successfully\"}), 200\n",
        "\n",
        "# 1. Individual Sales Representative Performance Analysis\n",
        "@app.route('/api/rep_performance', methods=['GET'])\n",
        "def rep_performance():\n",
        "    rep_id = request.args.get('rep_id')\n",
        "    if not rep_id:\n",
        "        return jsonify({\"error\": \"rep_id parameter is required\"}), 400\n",
        "\n",
        "    data = pd.read_json('sales_data.json')\n",
        "    individual_data = data[data['employee_id'] == int(rep_id)]  # Ensure column name matches\n",
        "\n",
        "    if individual_data.empty:\n",
        "        return jsonify({\"error\": f\"No data found for rep_id {rep_id}\"}), 404\n",
        "\n",
        "    formatted_data = format_individual_data(individual_data)\n",
        "\n",
        "    feedback = analyze_data(\n",
        "        formatted_data,\n",
        "        f\"Provide a performance analysis for sales representative {rep_id} based on the following data:\"\n",
        "    )\n",
        "    return jsonify({\"feedback\": feedback})\n",
        "\n",
        "# 2. Overall Sales Team Performance Summary\n",
        "\n",
        "@app.route('/api/team_performance', methods=['GET'])\n",
        "def team_performance():\n",
        "    try:\n",
        "        data = pd.read_json('sales_data.json')\n",
        "\n",
        "        # Summarize the data\n",
        "        total_revenue = data['revenue_confirmed'].sum()\n",
        "        total_tours_booked = data['tours_booked'].sum()\n",
        "        avg_close_rate = data['avg_close_rate_30_days'].mean()\n",
        "\n",
        "        # Create a prompt for the LLM\n",
        "        prompt = (\n",
        "            f\"The sales team has a total revenue of {total_revenue}, \"\n",
        "            f\"total tours booked: {total_tours_booked}, \"\n",
        "            f\"and an average close rate of {avg_close_rate}. \"\n",
        "            \"Provide a summary of the overall team performance.\"\n",
        "        )\n",
        "\n",
        "        # Update this line to include the query\n",
        "        feedback = analyze_data(prompt, \"provide a summary of overall team performance\")\n",
        "\n",
        "        return jsonify({\"feedback\": feedback}), 200\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/performance_trends', methods=['GET'])\n",
        "def performance_trends():\n",
        "    time_period = request.args.get('time_period')\n",
        "\n",
        "    try:\n",
        "        data = pd.read_json('sales_data.json')\n",
        "\n",
        "        if data.empty:\n",
        "            return jsonify({\"error\": \"No sales data available\"}), 404\n",
        "\n",
        "        # Ensure the 'dated' column is in datetime format\n",
        "        data['dated'] = pd.to_datetime(data['dated'], errors='coerce')\n",
        "\n",
        "        # Group data based on the time period and sum only numeric columns\n",
        "        if time_period == 'yearly':\n",
        "            trends = data.groupby(data['dated'].dt.year).sum(numeric_only=True)\n",
        "        elif time_period == 'monthly':\n",
        "            trends = data.groupby(data['dated'].dt.to_period('M')).sum(numeric_only=True)\n",
        "        elif time_period == 'quarterly':\n",
        "            trends = data.groupby(data['dated'].dt.to_period('Q')).sum(numeric_only=True)\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Invalid time_period value\"}), 400\n",
        "\n",
        "        # Create a summary or insights based on trends\n",
        "        feedback = f\"Trends for {time_period}: {trends.to_json()}\"\n",
        "\n",
        "        return jsonify({\"feedback\": feedback}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "def filter_data_by_time_period(data, period):\n",
        "    # Implement logic to filter or summarize data based on the specified time period\n",
        "    # For now, let's return all data as a placeholder\n",
        "    return data\n",
        "\n",
        "# Home route\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Hello from Flask in Colab!\"\n",
        "\n",
        "# Start the ngrok tunnel and run the Flask app\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5azJ1UxngKi",
        "outputId": "9cee34f0-cc03-4226-cacd-1e8227b894e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://c1c6-104-155-230-138.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:49:26] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:49:26] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:49:27] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:49:38] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:49:46] \"GET /api/performance_trends?time_period=yearly HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:50:20] \"GET /api/performance_trends?time_period=monthly HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:54:18] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:54:20] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:54:28] \"\u001b[31m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:54:39] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:56:29] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:56:37] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:58:03] \"\u001b[33mGET /individual/Jim%20Lee%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:58:44] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 12:59:25] \"\u001b[31m\u001b[1mGET /upload HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:01:32] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:01:54] \"\u001b[33mGET /individual/Jim%20Lee%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:01:58] \"\u001b[33mGET /individual/Jim%20Lee%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:03:59] \"\u001b[33mGET /api/team_performance%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:09] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:11] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:12] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:12] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:12] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:37] \"\u001b[33mGET /api/team_performance%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:39] \"\u001b[33mGET /api/team_performance%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:04:47] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:05:10] \"\u001b[33mGET /api/team_performance%0A HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:05:57] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:05:58] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:05:59] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:05:59] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:06:48] \"GET /individual/Jim%20Lee HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:07:29] \"GET /individual/Jim%20Lee HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:08:54] \"GET /individual/Jim%20Lee HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:15:22] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:15:43] \"GET /individual/Jim%20Lee HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:20:36] \"GET /api/performance_trends?time_period=yearly HTTP/1.1\" 200 -\n",
            "Your max_length is set to 150, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:21:28] \"HEAD / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Sep/2024 13:21:37] \"GET /api/team_performance HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}